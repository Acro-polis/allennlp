{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "csqa_directory=\"/home/ubuntu/Desktop/CSQA_v9/train\" \n",
    "wikidata_directory=\"/home/ubuntu/Desktop/wikidata\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(os.path.join(os.path.abspath(''), os.pardir)))))\n",
    "\n",
    "from allennlp.common.testing.test_case import AllenNlpTestCase\n",
    "from allennlp.common import Params\n",
    "from allennlp.data.dataset_readers.semantic_parsing.csqa.csqa import CSQADatasetReader\n",
    "from allennlp.state_machines.states.grammar_statelet import GrammarStatelet\n",
    "from allennlp.state_machines.states.grammar_based_search_state import GrammarBasedSearchState\n",
    "from allennlp.semparse.domain_languages.csqa_language import CSQALanguage\n",
    "from allennlp.semparse.domain_languages.csqa_language import Entity, Predicate\n",
    "from allennlp.semparse.domain_languages import START_SYMBOL\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'lazy': True,\n",
    "          'kg_path':  f'{wikidata_directory}/wikidata_short_1_2_rev.p',\n",
    "          'kg_type_data_path':  f'{wikidata_directory}/par_child_dict_full.p',\n",
    "          'entity_id2string_path':  f'{AllenNlpTestCase.FIXTURES_ROOT}/data/csqa/sample_entity_id2string.json',\n",
    "          'predicate_id2string_path': f'{AllenNlpTestCase.FIXTURES_ROOT}/data/csqa/filtered_property_wikidata4.json'\n",
    "         }\n",
    "\n",
    "reader = CSQADatasetReader.from_params(Params(params))\n",
    "# qa_path = f'{AllenNlpTestCase.FIXTURES_ROOT}/data/csqa/sample_qa.json'\n",
    "qa_path = f'{AllenNlpTestCase.FIXTURES_ROOT}/data/csqa/sample_train'\n",
    "dataset = reader.read(qa_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_state(language):\n",
    "    language_valid_actions = defaultdict(list)\n",
    "    for production_rule in language.all_possible_productions():\n",
    "        lhs, rhs = production_rule.split(' -> ')\n",
    "        language_valid_actions[lhs].append(rhs)\n",
    "    return GrammarBasedSearchState(action_history=[],\n",
    "                                   nonterminal_stack=[START_SYMBOL],\n",
    "                                   valid_actions=language_valid_actions,\n",
    "                                   is_nonterminal=language.is_nonterminal)\n",
    "\n",
    "def search(language, expected_result, verbose=False, max_depth=17, max_time=30, stop_after_n_found=1):\n",
    "    language.set_search_modus()\n",
    "    states, correct_action_sequences = [get_initial_state(language)], []\n",
    "    depth = 0\n",
    "    finished = False\n",
    "    start_search_time = time.time()\n",
    "    \n",
    "    while depth < max_depth:\n",
    "        if time.time() - start_search_time > max_time:\n",
    "            break\n",
    "        depth += 1\n",
    "        next_states = []\n",
    "        if finished: break\n",
    "        for state in states:\n",
    "            if state.is_finished():\n",
    "                if language.execute_action_sequence(state.action_history) == expected_result:\n",
    "                    correct_action_sequences.append(state.action_history)\n",
    "                    if len(correct_action_sequences) >= stop_after_n_found:\n",
    "                        finished = True\n",
    "                        break\n",
    "                continue\n",
    "\n",
    "            state_valid_actions = [v for v in state.get_valid_actions() if\n",
    "                                   v.count(',') + v.count(':') + 1 <= (max_depth - depth)]            \n",
    "\n",
    "            if depth < max_depth:\n",
    "                for valid_action in state_valid_actions:\n",
    "                    if depth == 1:\n",
    "                        if (isinstance(expected_result, set) and 'Set' not in valid_action) or \\\n",
    "                           (isinstance(expected_result, int) and 'Number' not in valid_action) or \\\n",
    "                           (isinstance(expected_result, bool) and 'bool' not in valid_action):\n",
    "                            continue\n",
    "                                \n",
    "                    production_rule = state._nonterminal_stack[-1] + \" -> \" + valid_action\n",
    "                    next_states.append(state.take_action(production_rule))\n",
    "        states = next_states\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nfinished at depth {} in {} seconds\".format(depth, time.time()-instance_start_time))\n",
    "        \n",
    "    return correct_action_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_instance_info = True\n",
    "logical_form_result_dict = {}\n",
    "\n",
    "for i, instance in enumerate(dataset):\n",
    "\n",
    "    question = instance['question'].tokens\n",
    "    language = instance['world'].metadata\n",
    "    expected_result = instance['expected_result'].metadata\n",
    "    qa_id = instance['qa_id'].metadata\n",
    "\n",
    "    result_action_sequences = search(language, expected_result)\n",
    "    \n",
    "    logical_form_result_dict[qa_id] = result_action_sequences\n",
    "\n",
    "# pickle.dump(logical_form_result_dict, open(f'{AllenNlpTestCase.FIXTURES_ROOT}/data/csqa/sample_train_action_sequences.p', \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
